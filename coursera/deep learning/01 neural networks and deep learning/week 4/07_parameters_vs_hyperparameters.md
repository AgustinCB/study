# Parameters vs Hyperparameters

In this lesson we will cover what are hyperparameters and how they impact the learning algorithm.

The parameters are usually W and B.

The hyperparameters are the learning rate (alpha), the number of iterations for gradient descent, the number of hidden units (L), the number of hidden units (N), the choice of activation function... They all control the parameters W and B, so they're called hyperparameters.

Applied deep learning is a very empirical process, in which you try different hyperparameters and based on the outcome you change them again still you arrive to something that makes you happy.
